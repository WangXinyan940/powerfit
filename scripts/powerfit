#! /usr/bin/python
# -*- coding: utf-8 -*-
from __future__ import print_function, division, absolute_import

import os
from sys import stdout
from time import time
from argparse import ArgumentParser, FileType
import multiprocessing as mp

import numpy as np

from powerfit import PDB, Volume, PowerFitter, Solutions
from powerfit.rotations import proportional_orientations, quat_to_rotmat
from powerfit.helpers import get_queue
from powerfit import volume

import logging
logging.basicConfig(filename='powerfit.log', level=logging.INFO,
        format='%(asctime)s %(message)s')

def parse_args():

    p = ArgumentParser()

    p.add_argument('model', type=file,
            help='Atomic model to be fitted in the density. ' +\
                 'Format should either be PDB or mmCIF')
    p.add_argument('map', type=FileType('rb'),
            help='Target density map to fit the model in. ' +\
                 'Data should either be in CCP4 or MRC format')

    p.add_argument('resolution', type=float,
            help='Resolution of map in angstrom')

    p.add_argument('-a', '--angle', dest='angle', type=float, default=10,
            help='Rotational sampling density in degree. Increasing ' +\
                 'this number by a factor of 2 results in approximately ' +\
                 '8 times more rotations sampled.')

    p.add_argument('-l', '--laplace', dest='laplace', action='store_true',
            help='Use the Laplace pre-filter density data. ' +\
                 'Can be combined ' +\
                 'with the core-weighted local cross-correlation.')

    p.add_argument('-cw', '--core-weighted', dest='core_weighted', action='store_true',
            help='Use core-weighted local cross-correlation score. ' +\
                 'Can be combined with the Laplace pre-filter.')

    p.add_argument('-n', '--num', dest='num', type=int, default=10,
            help='Number of models written to file. This number ' +\
                 'will be capped if less solutions are found as requested.')

    p.add_argument('-g', '--gpu', dest='gpu', action='store_true',
            help='Off-load the intensive calculations to the GPU. ' +\
                 'If none is found, the CPU-version is used instead.')

    p.add_argument('-p', '--nproc', dest='nproc', type=int, default=1,
            help='Number of processors used during search. ' +\
                 'The number will be capped at the total number ' +\
                 'of available processors on your machine.')

    return p.parse_args()


def run_powerfit_instance(model, vol, rotmat, args, n):

    pf = PowerFitter()
    pf.map = vol
    pf.model = model
    pf.rotations = rotmat

    pf.resolution = args.resolution
    pf.laplace = args.laplace
    pf.core_weighted = args.core_weighted

    sol = pf.search()
    sol.save('lcc_{:d}.mrc'.format(n),
            'rotmat_{:d}.npy'.format(n),
            'rotmat_ind_{:d}.npy'.format(n))


def cpu_powerfit(model, vol, rotmat, args):

        # determine the number of jobs that should be created
        nrot = rotmat.shape[0]
        write('Requested number of processes: {:d}'.format(args.nproc))
        try:
            jobs = min(mp.cpu_count(), args.nproc)
            write('Maximum allowed processes: {:d}'.format(mp.cpu_count()))
        except NotImplementedError:
            jobs = args.nproc
        jobs = min(jobs, nrot)
        nrot_per_job = nrot//jobs

        write('Number of jobs created: {:d}'.format(jobs))
        write('Rotations sampled per job: {:d}'.format(nrot_per_job))

        write('Creating jobs.')
        processes = []
        for n in range(jobs):

            init_rot = n*nrot_per_job
            end_rot = init_rot + nrot_per_job
            if n == (jobs - 1):
                end_rot = None

            sub_rotmat = rotmat[init_rot: end_rot]

            processes.append(mp.Process(target=run_powerfit_instance,
                    args=(model, vol, sub_rotmat, args, n)))

        write('Starting jobs.')
        for n in range(jobs):
            processes[n].start()

        write('Waiting for jobs to end.')
        for n in range(jobs):
            processes[n].join()

        # combine results
        write('All jobs done.')
        write('Combining results.')
        best_lcc = Volume.fromfile('lcc_0.mrc')
        best_rotmat_ind = np.load('rotmat_ind_0.npy')
        for n in range(1, jobs):
            f_lcc= 'lcc_{:d}.mrc'.format(n)
            f_rotmat_ind = 'rotmat_ind_{:d}.npy'.format(n)
            lcc = Volume.fromfile(f_lcc)
            rotmat_ind = np.load(f_rotmat_ind) + nrot_per_job*n

            ind = lcc.array > best_lcc.array
            best_lcc.array[ind] = lcc.array[ind]
            best_rotmat_ind[ind] = rotmat_ind[ind]
        sol = Solutions(best_lcc, rotmat, best_rotmat_ind)

        write('Removing intermediate files')
        for n in range(jobs):
            f_lcc= 'lcc_{:d}.mrc'.format(n)
            f_rotmat_ind = 'rotmat_ind_{:d}.npy'.format(n)
            f_rotmat = 'rotmat_{:d}.npy'.format(n)
            os.remove(f_lcc)
            os.remove(f_rotmat_ind)
            os.remove(f_rotmat)

        return sol


def gpu_powerfit(queue, model, vol, rotmat, args):

    pf = PowerFitter()
    pf.map = vol
    pf.model = model
    pf.rotations = rotmat

    pf.resolution = args.resolution
    pf.laplace = args.laplace
    pf.core_weighted = args.core_weighted
    pf.queue = queue

    sol = pf.search()

    return sol

def write(line):
    if stdout.isatty():
        print(line)
    logging.info(line)

def main():

    args = parse_args()

    time0 = time()


    vol = Volume.fromfile(args.map)
    write('Density data read from: {:s}'.format(args.map.name))
    write('Resolution of data: {:.2f}'.format(args.resolution))
    write('Initial shape of density data: {:}'.format(str(vol.shape)))

    resampling_factor = vol.voxelspacing/(0.25*args.resolution)
    if resampling_factor < 0.9:
        write('Old voxel spacing: {:.2f}'.format(vol.voxelspacing))
        vol = volume.resample(vol, factor=resampling_factor)
        write('Resamped density to 1/4 of resolution voxel spacing')
        write('New voxel spacing: {:.2f}'.format(vol.voxelspacing))
        write('Shape of density data reduced to: {:}'.format(str(vol.shape)))

    vol = volume.trim(vol, 0.1*vol.array.max())
    vol = volume.resize_radix235(vol)
    write('Final shape of density data after trimming and resizing: {:}'.format(str(vol.shape)))

    model = PDB.fromfile(args.model)
    write('High-resolution model read from: {:s}'.format(args.model.name))

    q, w, a = proportional_orientations(args.angle)
    rotmat = quat_to_rotmat(q)
    write(u'Requested rotational sampling density: {:.2f}\N{DEGREE SIGN}'.format(args.angle))
    write(u'Real rotational sampling density: {:.2f}\N{DEGREE SIGN}.'.format(a))
    write('Total number of rotations sampled: {:d}'.format(len(rotmat)))

    write('Laplace pre-filter: {:}'.format(args.laplace))
    write('Core-weighted local cross correlation: {:}'.format(args.core_weighted))

    queue = None
    if args.gpu:
        queue = get_queue()

    if queue is None:
        if args.gpu:
            write('GPU-queue not found. Falling back on CPU-implementation.')
        write('Using CPU-version.')

        sol = cpu_powerfit(model, vol, rotmat, args)
    else:
        write('Using GPU-accelerated search.')
        sol = gpu_powerfit(queue, model, vol, rotmat, args)

    write('Searching done. Analyzing solutions.')
    sol.generate_local_solutions()
    write('Found {:d} non-redundant solutions.'.format(len(sol._local_solutions)))
    write('Saving raw results.')
    sol.save()
    write('Writing top {:d} models to file.'.format(args.num))
    sol.write_pdb(model, num=args.num)
    sol.write_local_solutions()

    tot_time = time() - time0
    m, s = divmod(int(round(tot_time)), 60)
    write('Total time required: {:d}m {:d}s'.format(m ,s))


if __name__=='__main__':
    main()
